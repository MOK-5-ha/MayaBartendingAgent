{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen AI Intensive Course Capstone 2025Q1: Bartending Agent ðŸ¸ðŸº"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: ðŸ¥‚\n",
    "\n",
    "Proof-of-Concept for an agentic AI that can take customer orders, make recommendations, and engage with customers with potentially meaningful conversations, all while maintaining a friendly and professional demeanor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it Works: ðŸ«—\n",
    "\n",
    "Users place orders through the Gradio UI, which the agent processes. The agent then engages in small talk and, after several exchanges, asks if the user wants another drink. When finished, the agent tallies the tab and thanks the user for their visit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capabilities Used: ðŸ¦¾\n",
    "\n",
    "- **Function Calling**:\n",
    "The agent uses LangChain and Gemini API function calling to process user orders and interact with tools (e.g., menu retrieval, order management).\n",
    "\n",
    "- **Agent**:\n",
    "The notebook implements an agentic workflow, where the AI acts as a bartender, managing conversation, state, and tool invocation.\n",
    "\n",
    "- **Retrieval Augmented Generation (RAG)**:\n",
    "The code includes logic for augmenting responses with external information (e.g., menu, order state).\n",
    "\n",
    "- **Vector search/vector store/vector database**:\n",
    "Via chromadb, vector search/storage is supported for use in RAG.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TCdSlfrF8Xx"
   },
   "source": [
    "# Setup and Installation ðŸ’¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx_QR3iBF_8h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai>=0.3.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (0.8.4)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (9.1.2)\n",
      "Requirement already satisfied: gradio>=4.0.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (5.24.0)\n",
      "Requirement already satisfied: cartesia>=2.0.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-google-genai in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (2.0.10)\n",
      "Requirement already satisfied: langchain-core in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (0.3.51)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (2.166.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (2.38.0)\n",
      "Requirement already satisfied: protobuf in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (5.29.4)\n",
      "Requirement already satisfied: pydantic in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (2.11.3)\n",
      "Requirement already satisfied: tqdm in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-generativeai>=0.3.0) (4.13.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0) (1.26.1)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (24.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (4.9.0)\n",
      "Requirement already satisfied: audioop-lts<1.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.2.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (2.2.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (3.10.16)\n",
      "Requirement already satisfied: packaging in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (11.1.0)\n",
      "Requirement already satisfied: pydub in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.11.5)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.15.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio>=4.0.0) (0.34.0)\n",
      "Requirement already satisfied: fsspec in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio-client==1.8.0->gradio>=4.0.0) (2025.3.2)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from gradio-client==1.8.0->gradio>=4.0.0) (15.0.1)\n",
      "Requirement already satisfied: aiohttp>=3.10.10 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from cartesia>=2.0.0) (3.11.16)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from cartesia>=2.0.0) (0.4.0)\n",
      "Requirement already satisfied: iterators>=0.2.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from cartesia>=2.0.0) (0.2.0)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from cartesia>=2.0.0) (2.33.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from langchain-core) (0.3.30)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from aiohttp>=3.10.10->cartesia>=2.0.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from aiohttp>=3.10.10->cartesia>=2.0.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from aiohttp>=3.10.10->cartesia>=2.0.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from aiohttp>=3.10.10->cartesia>=2.0.0) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from aiohttp>=3.10.10->cartesia>=2.0.0) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from aiohttp>=3.10.10->cartesia>=2.0.0) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from aiohttp>=3.10.10->cartesia>=2.0.0) (1.19.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio>=4.0.0) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from anyio<5.0,>=3.0->gradio>=4.0.0) (1.3.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-api-core->google-generativeai>=0.3.0) (1.69.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-api-core->google-generativeai>=0.3.0) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-auth>=2.15.0->google-generativeai>=0.3.0) (4.9)\n",
      "Requirement already satisfied: certifi in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from httpx>=0.24.1->gradio>=4.0.0) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from httpx>=0.24.1->gradio>=4.0.0) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio>=4.0.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from huggingface-hub>=0.28.1->gradio>=4.0.0) (3.18.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio>=4.0.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio>=4.0.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from pandas<3.0,>=1.0->gradio>=4.0.0) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from pydantic->google-generativeai>=0.3.0) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from pydantic->google-generativeai>=0.3.0) (0.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from typer<1.0,>=0.12->gradio>=4.0.0) (14.0.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-api-python-client->google-generativeai>=0.3.0) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-api-python-client->google-generativeai>=0.3.0) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-api-python-client->google-generativeai>=0.3.0) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai>=0.3.0) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai>=0.3.0) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai>=0.3.0) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio>=4.0.0) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai>=0.3.0) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai>=0.3.0) (2.4.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pretermodernist/MOK-5-ha/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install \"google-generativeai>=0.3.0\" \"tenacity>=8.2.3\" \"gradio>=4.0.0\" \"cartesia>=2.0.0\" \"python-dotenv>=1.0.0\" langchain-google-genai langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries ðŸ“š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqKzi04BGEKW"
   },
   "outputs": [],
   "source": [
    "# Common libraries\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import re # For parsing the menu\n",
    "import io\n",
    "import base64\n",
    "import requests\n",
    "import json # For parsing tool arguments if needed\n",
    "from typing import Dict, List, Optional, Tuple, Any\n",
    "\n",
    "# Agent UI\n",
    "import gradio as gr\n",
    "from gradio.themes.utils import colors, fonts, sizes\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Generative AI / Agent packages\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage\n",
    "from langchain_core.tools import tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkTkJ89iGKTd"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Key Setup (WIP) ðŸ”\n",
    "\n",
    "Blank for now. Fill in later when on Kaggle.\n",
    "\n",
    "Include section on how to setup Cartesia API key and what it's for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyccDKQIGxxT"
   },
   "source": [
    "# Bartending Agent Implementation ðŸ¤–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9644cbe",
   "metadata": {
    "id": "genai_version_cell"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genai version: 0.8.4\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.generativeai as genai\n",
    "    from google.api_core import retry as core_retry # For potential core retries\n",
    "    from google.generativeai import types as genai_types # For specific types if needed later\n",
    "except ImportError:\n",
    "    print(\"Error: google.generativeai library not found.\")\n",
    "    print(\"Please install it using: pip install google-generativeai\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"genai version:\",genai.__version__)\n",
    "\n",
    "# Tenacity for retries on specific functions\n",
    "try:\n",
    "    from tenacity import (\n",
    "        retry as tenacity_retry, # Alias to avoid confusion with google.api_core.retry\n",
    "        stop_after_attempt,\n",
    "        wait_exponential,\n",
    "        retry_if_exception_type,\n",
    "        before_sleep_log\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"Warning: tenacity library not found. Retries on API calls will not be enabled.\")\n",
    "    print(\"Install it using: pip install tenacity\")\n",
    "    # Define a dummy decorator if tenacity is missing\n",
    "    def tenacity_retry(*args, **kwargs):\n",
    "        def decorator(func):\n",
    "            return func\n",
    "        return decorator\n",
    "    RETRYABLE_EXCEPTIONS = (Exception,) # Fallback to generic exception\n",
    "    before_sleep_log = lambda logger, level: None # Dummy function\n",
    "\n",
    "try:\n",
    "    from cartesia import Cartesia\n",
    "    from cartesia.tts import OutputFormat_Raw, TtsRequestIdSpecifier\n",
    "except ImportError:\n",
    "    print(\"Error: Cartesia library not found.\")\n",
    "    print(\"Please ensure it's installed with: pip install cartesia\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "FB4uGl8iHjnm"
   },
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# Load Gemini API key from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in environment variables. Please set it in your .env file.\")\n",
    "\n",
    "# Get Cartesia API Key (Ensure this is set in your .env file or system environment)\n",
    "CARTESIA_API_KEY = os.getenv(\"CARTESIA_API_KEY\") # Load Cartesia key\n",
    "\n",
    "if not CARTESIA_API_KEY:\n",
    "    logger.error(\"FATAL: CARTESIA_API_KEY not found in environment variables or .env file.\")\n",
    "    # Decide if TTS is optional or required. Assuming required for now.\n",
    "    raise EnvironmentError(\"CARTESIA_API_KEY is required but not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_lebELKHHmUL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:16:41,166 - __main__ - INFO - Successfully initialized Cartesia client.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Cartesia Client (ONCE at module load)\n",
    "try:\n",
    "    # Replace \"your-chosen-voice-id\" with an actual valid ID from Cartesia\n",
    "    CARTESIA_VOICE_ID = \"6f84f4b8-58a2-430c-8c79-688dad597532\" # Example placeholder ID - CHANGE THIS\n",
    "    if not CARTESIA_VOICE_ID or \"your-chosen-voice-id\" in CARTESIA_VOICE_ID:\n",
    "         logger.warning(\"CARTESIA_VOICE_ID is not set to a valid ID. Please edit bartending_agent.py.\")\n",
    "         # Decide if this is fatal. Maybe proceed without voice for now?\n",
    "\n",
    "    cartesia_client = Cartesia(\n",
    "        api_key=CARTESIA_API_KEY,\n",
    "        )\n",
    "    logger.info(\"Successfully initialized Cartesia client.\")\n",
    "    # Optional: Could add a check here to verify the voice ID exists using the client if possible\n",
    "except Exception as e:\n",
    "     logger.exception(\"Fatal: Failed to initialize Cartesia client.\")\n",
    "     raise RuntimeError(\"Cartesia client initialization failed.\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ng_t4TUIHwL7"
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_menu() -> str:\n",
    "    \"\"\"Provide the latest up-to-date menu.\"\"\"\n",
    "    # Note that this is just hard-coded text, but you could connect this to a live stock\n",
    "    # database, or you could use Gemini's multi-modal capabilities and take live photos of\n",
    "    # your cafe's chalk menu or the products on the counter and assmble them into an input.\n",
    "\n",
    "    return \"\"\"\n",
    "    MENU:\n",
    "    Cocktails with Liquor:\n",
    "    Daiquiri - $10.00\n",
    "    Martini - $13.00\n",
    "    Long Island - $12.00\n",
    "    Old Fashioned - $12.00\n",
    "    Negroni - $11.00\n",
    "    Cosmopolitan - $12.00\n",
    "    Manhattan - $12.00\n",
    "\n",
    "    Beer:\n",
    "    Tap Beer - $5.00\n",
    "    Classic Brew - $5.00\n",
    "    IPA - $6.00\n",
    "\n",
    "    Non-Alcoholic Beverages:\n",
    "    Water - $1.00\n",
    "    Iced Tea - $2.00\n",
    "    Lemonade - $2.00\n",
    "    Soda - $3.00\n",
    "\n",
    "    Modifiers:\n",
    "    Liquor Options: Vodka, Tequila, Gin, Whiskey, Rum, Brandy; Default option: Vodka\n",
    "    Special requests: any reasonable modification that does not involve items not on the menu, for example: 'shaken', 'stirred', 'neat', 'dry', etc.\n",
    "\n",
    "    â€œneatâ€ means no ice, straight from the bottle.\n",
    "    â€œon the rocksâ€ means served with ice.\n",
    "    â€œdryâ€ is used for martinis to specify less vermouth.\n",
    "    â€œdirtyâ€ means adding olive juice to a martini.\n",
    "    â€œperfectâ€ is a 50/50 mix of dry and sweet vermouth, often for a Manhattan.\n",
    "    â€œChaserâ€ means a separate drink to follow, typically non-alcoholic.\n",
    "  \"\"\"\n",
    "\n",
    "# --- Tenacity retry decorator for _call_gemini_api ---\n",
    "# ... (keep the @tenacity_retry decorator as it was) ...\n",
    "@tenacity_retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_exponential(multiplier=1, min=2, max=10),\n",
    "    #retry=retry_if_exception_type(RETRYABLE_EXCEPTIONS),\n",
    "    before_sleep=before_sleep_log(logger, logging.WARNING) if callable(before_sleep_log) else None, # Check if callable\n",
    "    reraise=True # Re-raise the exception if all retries fail\n",
    ")\n",
    "def _call_gemini_api(prompt_content: List[Dict], config: Dict) -> genai.types.GenerateContentResponse: # Adjusted input type hint\n",
    "    \"\"\"Internal function to call the Gemini API with retry logic (Stateless).\"\"\"\n",
    "    logger.debug(\"Calling Gemini API...\")\n",
    "    # Uses the globally initialized 'model'\n",
    "    response = model.generate_content(\n",
    "        contents=prompt_content, # Correct parameter name is 'contents'\n",
    "        generation_config=config,\n",
    "        # safety_settings can be added here if needed\n",
    "    )\n",
    "    logger.debug(\"Gemini API call successful.\")\n",
    "    return response\n",
    "\n",
    "\n",
    "# --- New LangGraph-style System Prompt ---\n",
    "# ... (keep BARTENDERBOT_SYSINT definition as it was) ...\n",
    "BARTENDERBOT_SYSINT = (\n",
    "    \"You are a Bartender-Bot, an interactive drink ordering system. A human will talk to you about the \"\n",
    "    \"available products you have and you will answer any questions about menu items and their prices (and only about \"\n",
    "    \"menu items - no off-topic discussion, but you can chat about the products and their history). \"\n",
    "    \"The customer will place an order for 1 or more items from the menu, which you will structure \"\n",
    "    \"and send to the ordering system after confirming the order with the human. \"\n",
    "    \"\\n\\n\"\n",
    "    \"Add items to the customer's order with add_to_order, and reset the order with clear_order. \"\n",
    "    \"To see the contents of the order so far, call get_order (this is shown to you, not the user) \"\n",
    "    \"Always confirm_order with the user (double-check) before calling place_order. Calling confirm_order will \"\n",
    "    \"display the order items to the user and returns their response to seeing the list. Their response may contain modifications. \"\n",
    "    \"Always verify and respond with drink and modifier names from the MENU before adding them to the order. \"\n",
    "    \"If you are unsure a drink or modifier matches those on the MENU, ask a question to clarify or redirect. \"\n",
    "    \"You only have the modifiers listed on the menu. \"\n",
    "    \"Once the customer has finished ordering items, Call confirm_order to ensure it is correct then make \"\n",
    "    \"any necessary updates and then call place_order. Once place_order has returned, thank the user for their business and \"\n",
    "    \"politely say their order will be ready shortly!\"\n",
    "    \"\\n\\n\"\n",
    "    \"The bar's name is MOK 5-ha, pronounced as 'Moksha'. If a customer asks about the name, explain that:\\n\"\n",
    "    \"Moksha represents liberation from the cycle of rebirth (samsara) and union with the divine. It is achieved through spiritual enlightenment, freeing the soul from karma and earthly attachments to attain eternal bliss.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jMM9jggIVHVV"
   },
   "outputs": [],
   "source": [
    "# --- Tool Definitions ---\n",
    "\n",
    "# (Keep your existing @tool def get_menu() -> str: ... here)\n",
    "\n",
    "# Helper function to parse the menu string (you might need to adjust regex based on exact format)\n",
    "def _parse_menu_items(menu_str: str) -> Dict[str, float]:\n",
    "    items = {}\n",
    "    # Regex to find lines like \"Item Name - $Price.xx\"\n",
    "    # Handles potential variations in spacing\n",
    "    pattern = re.compile(r\"^\\s*(.+?)\\s*-\\s*\\$(\\d+\\.\\d{2})\\s*$\", re.MULTILINE)\n",
    "    matches = pattern.findall(menu_str)\n",
    "    for match in matches:\n",
    "        item_name = match[0].strip()\n",
    "        price = float(match[1])\n",
    "        items[item_name.lower()] = price # Store lowercase for easier matching\n",
    "    return items\n",
    "\n",
    "@tool\n",
    "def add_to_order(item_name: str, quantity: int = 1) -> str:\n",
    "    \"\"\"\n",
    "    Adds the specified quantity of an item to the customer's order.\n",
    "    Use this AFTER verifying the item is on the menu.\n",
    "    Args:\n",
    "        item_name: The exact name of the item from the menu.\n",
    "        quantity: The number of this item to add (defaults to 1).\n",
    "    \"\"\"\n",
    "    global current_process_order_state # Use global to access state within this call\n",
    "\n",
    "    menu_str = get_menu.invoke({}) # Get the current menu # Get the current menu\n",
    "    menu_items = _parse_menu_items(menu_str)\n",
    "    item_lower = item_name.lower()\n",
    "\n",
    "    if item_lower in menu_items:\n",
    "        price = menu_items[item_lower]\n",
    "        for _ in range(quantity):\n",
    "            current_process_order_state['order'].append({\"name\": item_name, \"price\": price}) # Modify the state directly\n",
    "        logger.info(f\"Tool: Added {quantity} x '{item_name}' to order.\")\n",
    "        return f\"Successfully added {quantity} x {item_name} to the order.\"\n",
    "    else:\n",
    "        logger.warning(f\"Tool: Attempted to add item '{item_name}' not found in parsed menu.\")\n",
    "        # Try a fuzzy match maybe? For now, return error.\n",
    "        # Consider listing similar items if needed.\n",
    "        return f\"Error: Item '{item_name}' could not be found on the current menu. Please verify the item name.\"\n",
    "\n",
    "@tool\n",
    "def clear_order() -> str:\n",
    "    \"\"\"Removes all items from the current order.\"\"\"\n",
    "    global current_process_order_state\n",
    "    current_process_order_state['order'] = [] # Clear the state\n",
    "    logger.info(\"Tool: Cleared order.\")\n",
    "    return \"The order has been cleared.\"\n",
    "\n",
    "@tool\n",
    "def get_order() -> str:\n",
    "    \"\"\"Returns the current list of items in the order for the agent to see.\"\"\"\n",
    "    global current_process_order_state\n",
    "    order_list = current_process_order_state['order']\n",
    "    if not order_list:\n",
    "        return \"The order is currently empty.\"\n",
    "    order_details = \"\\n\".join([f\"- {item['name']} (${item['price']:.2f})\" for item in order_list])\n",
    "    total = sum(item['price'] for item in order_list)\n",
    "    return f\"Current Order:\\n{order_details}\\nTotal: ${total:.2f}\"\n",
    "\n",
    "@tool\n",
    "def confirm_order() -> str:\n",
    "    \"\"\"\n",
    "    Displays the current order to the user and asks for confirmation.\n",
    "    The user's response will be processed in the next turn.\n",
    "    \"\"\"\n",
    "    global current_process_order_state\n",
    "    order_list = current_process_order_state['order']\n",
    "    if not order_list:\n",
    "        return \"There is nothing in the order to confirm. Please add items first.\"\n",
    "\n",
    "    order_details = \"\\n\".join([f\"- {item['name']} (${item['price']:.2f})\" for item in order_list])\n",
    "    total = sum(item['price'] for item in order_list)\n",
    "    confirmation_request = f\"Here is your current order:\\n{order_details}\\nTotal: ${total:.2f}\\n\\nIs this correct? You can ask to add/remove items or proceed to place the order.\"\n",
    "    logger.info(\"Tool: Generated order confirmation request for user.\")\n",
    "    # This tool doesn't actually *place* the order, it just prepares the text for the LLM to relay\n",
    "    return confirmation_request # The LLM should incorporate this text into its response to the user\n",
    "\n",
    "@tool\n",
    "def place_order() -> str:\n",
    "    \"\"\"Finalizes and places the customer's confirmed order.\"\"\"\n",
    "    global current_process_order_state\n",
    "    order_list = current_process_order_state['order']\n",
    "    if not order_list:\n",
    "        return \"Cannot place an empty order. Please add items first.\"\n",
    "\n",
    "    # In a real system, this would interact with a POS or backend API.\n",
    "    # Here, we'll just log it and modify the state.\n",
    "    order_details = \", \".join([item['name'] for item in order_list])\n",
    "    total = sum(item['price'] for item in order_list)\n",
    "    logger.info(f\"Tool: Placing order: [{order_details}], Total: ${total:.2f}\")\n",
    "\n",
    "    # Mark order as finished (though 'finished' isn't explicitly in Gradio state)\n",
    "    # We can clear the order after placing it for this simple setup\n",
    "    current_process_order_state['order'] = [] # Clear order after placing\n",
    "    current_process_order_state['finished'] = True # Set a flag if needed later\n",
    "\n",
    "    return f\"Order placed successfully! Your items ({order_details}) totalling ${total:.2f} will be ready shortly.\"\n",
    "\n",
    "# List of all tools for the LLM\n",
    "tools = [get_menu, add_to_order, clear_order, get_order, confirm_order, place_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "P-mA2edJXlkb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:16:41,352 - __main__ - INFO - Successfully initialized LangChain ChatGoogleGenerativeAI model bound with tools.\n"
     ]
    }
   ],
   "source": [
    "# Model initialization\n",
    "\n",
    "# With the LangChain setup:\n",
    "try:\n",
    "    # Ensure GEMINI_API_KEY is set (e.g., from .env file or input)\n",
    "    if not GEMINI_API_KEY:\n",
    "        raise ValueError(\"GEMINI_API_KEY not found.\")\n",
    "\n",
    "    # Use ChatGoogleGenerativeAI and bind the tools\n",
    "    # Note: Use a model that supports tool calling well, like gemini-pro or newer flash/pro models\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.0-flash\", # Or \"gemini-pro\", etc. Check model compatibility\n",
    "        temperature=0.7,\n",
    "        max_output_tokens=2048,\n",
    "        google_api_key=GEMINI_API_KEY\n",
    "    ).bind_tools(tools) # Bind the list of tool functions\n",
    "\n",
    "    logger.info(f\"Successfully initialized LangChain ChatGoogleGenerativeAI model bound with tools.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.exception(f\"Fatal: Failed to initialize LangChain Gemini model: {str(e)}\")\n",
    "    raise RuntimeError(\n",
    "        f\"Failed to initialize LangChain Gemini model. Check API key and model name.\"\n",
    "    ) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_BOntx4XH5-J"
   },
   "outputs": [],
   "source": [
    "# --- New LangGraph-style System Prompt ---\n",
    "# (Note: The actual tools mentioned here like add_to_order are not yet implemented\n",
    "# in this specific file structure. The LLM will receive these instructions, but\n",
    "# the surrounding code doesn't execute LangGraph tools.)\n",
    "BARTENDERBOT_SYSINT = (\n",
    "    \"You are a Bartender-Bot, an interactive drink ordering system. A human will talk to you about the \"\n",
    "    \"available products you have and you will answer any questions about menu items and their prices (and only about \"\n",
    "    \"menu items - no off-topic discussion, but you can chat about the products and their history). \"\n",
    "    \"The customer will place an order for 1 or more items from the menu, which you will structure \"\n",
    "    \"and send to the ordering system after confirming the order with the human. \"\n",
    "    \"\\n\\n\"\n",
    "    \"Add items to the customer's order with add_to_order, and reset the order with clear_order. \"\n",
    "    \"To see the contents of the order so far, call get_order (this is shown to you, not the user) \"\n",
    "    \"Always confirm_order with the user (double-check) before calling place_order. Calling confirm_order will \"\n",
    "    \"display the order items to the user and returns their response to seeing the list. Their response may contain modifications. \"\n",
    "    \"Always verify and respond with drink and modifier names from the MENU before adding them to the order. \"\n",
    "    \"If you are unsure a drink or modifier matches those on the MENU, ask a question to clarify or redirect. \"\n",
    "    \"You only have the modifiers listed on the menu. \"\n",
    "    \"Once the customer has finished ordering items, Call confirm_order to ensure it is correct then make \"\n",
    "    \"any necessary updates and then call place_order. Once place_order has returned, thank the user for their business and \"\n",
    "    \"politely say their order will be ready shortly!\"\n",
    "    \"\\n\\n\"\n",
    "    \"The bar's name is MOK 5-ha, pronounced as 'Moksha'. If a customer asks about the name, explain that:\\n\"\n",
    "    \"Moksha represents liberation from the cycle of rebirth (samsara) and union with the divine. It is achieved through spiritual enlightenment, freeing the soul from karma and earthly attachments to attain eternal bliss.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Global variable to hold state accessible by tools within a single process_order call\n",
    "current_process_order_state = {'order': [], 'finished': False}\n",
    "\n",
    "def process_order(\n",
    "    user_input_text: str,\n",
    "    current_session_history: List[Dict[str, str]],\n",
    "    current_session_order: List[Dict[str, float]]\n",
    ") -> Tuple[str, List[Dict[str, str]], List[Dict[str, float]]]:\n",
    "    \"\"\"\n",
    "    Processes user input using LangChain LLM with tool calling, updates state.\n",
    "    \"\"\"\n",
    "    global menu, llm, current_process_order_state # Access global LLM and menu dict\n",
    "\n",
    "    if not user_input_text:\n",
    "        logger.warning(\"Received empty user input.\")\n",
    "        return \"Please tell me what you'd like to order.\", current_session_history, current_session_order\n",
    "\n",
    "    # --- Initialize state for this specific call ---\n",
    "    # Copy Gradio state to our temporary global state accessible by tools\n",
    "    # NOTE: This global approach is simple for this example but not ideal for concurrent requests.\n",
    "    # A better approach in a real app might involve classes or context managers.\n",
    "    current_process_order_state['order'] = current_session_order[:] # Copy list\n",
    "    current_process_order_state['finished'] = False # Reset finished flag for this turn\n",
    "\n",
    "    # Prepare message history for LangChain model\n",
    "    messages = []\n",
    "    # Add System Prompt\n",
    "    messages.append(SystemMessage(content=BARTENDERBOT_SYSINT))\n",
    "    # Add Menu (as system/context info - could also be retrieved via tool call if user asks)\n",
    "    # This explicitly calls the tool using the correct interface, providing a dummy input(the empty dictionary) that satisfies the method signature, even though the get_menu function itself doesn't use it.\n",
    "    messages.append(SystemMessage(content=\"\\nHere is the menu:\\n\" + get_menu.invoke({}))) # Use invoke()\n",
    "\n",
    "    # Convert Gradio history to LangChain message types\n",
    "    history_limit = 10\n",
    "    limited_history = current_session_history[-history_limit:]\n",
    "    for entry in limited_history:\n",
    "        role = entry.get(\"role\")\n",
    "        content = entry.get(\"content\", \"\")\n",
    "        if role == \"user\":\n",
    "            messages.append(HumanMessage(content=content))\n",
    "        elif role == \"assistant\":\n",
    "            messages.append(AIMessage(content=content)) # Assuming simple text responses previously\n",
    "\n",
    "    # Add the latest user input\n",
    "    messages.append(HumanMessage(content=user_input_text))\n",
    "\n",
    "    logger.info(f\"Processing user input for session: {user_input_text}\")\n",
    "    # logger.debug(f\"Messages sent to LLM: {messages}\")\n",
    "\n",
    "    try:\n",
    "        # --- LLM Interaction Loop (Handles Tool Calls) ---\n",
    "        while True:\n",
    "            # Invoke the LLM with current messages\n",
    "            ai_response: AIMessage = llm.invoke(messages)\n",
    "            # logger.debug(f\"LLM Response Object: {ai_response}\")\n",
    "\n",
    "            # Append the AI's response (could be text or tool call request)\n",
    "            messages.append(ai_response)\n",
    "\n",
    "            if not ai_response.tool_calls:\n",
    "                # No tool calls requested, this is the final response to the user\n",
    "                agent_response_text = ai_response.content\n",
    "                break # Exit the loop\n",
    "\n",
    "            # --- Tool Call Execution ---\n",
    "            logger.info(f\"LLM requested tool calls: {ai_response.tool_calls}\")\n",
    "            tool_messages = [] # Collect tool results\n",
    "            for tool_call in ai_response.tool_calls:\n",
    "                tool_name = tool_call.get(\"name\")\n",
    "                tool_args = tool_call.get(\"args\", {})\n",
    "                tool_id = tool_call.get(\"id\") # Important for ToolMessage\n",
    "\n",
    "                # Find the corresponding tool function\n",
    "                selected_tool = next((t for t in tools if t.name == tool_name), None)\n",
    "\n",
    "                if selected_tool:\n",
    "                    try:\n",
    "                        # Execute the tool function with its arguments\n",
    "                        # Arguments are usually dicts, unpack if needed or pass as is\n",
    "                        tool_output = selected_tool.invoke(tool_args)\n",
    "                        logger.info(f\"Executed tool '{tool_name}' with args {tool_args}. Output: {tool_output}\")\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error executing tool '{tool_name}': {e}\")\n",
    "                        tool_output = f\"Error executing tool {tool_name}: {e}\"\n",
    "\n",
    "                    # Append the result as a ToolMessage\n",
    "                    tool_messages.append(ToolMessage(content=str(tool_output), tool_call_id=tool_id))\n",
    "                else:\n",
    "                    logger.error(f\"Tool '{tool_name}' requested by LLM not found.\")\n",
    "                    tool_messages.append(ToolMessage(content=f\"Error: Tool '{tool_name}' not found.\", tool_call_id=tool_id))\n",
    "\n",
    "            # Add the tool results to the message history\n",
    "            messages.extend(tool_messages)\n",
    "            # Continue the loop to send results back to LLM\n",
    "            logger.info(\"Sending tool results back to LLM...\")\n",
    "\n",
    "        # --- End of LLM Interaction Loop ---\n",
    "\n",
    "        # Final response text is now set\n",
    "        logger.info(f\"Final agent response: {agent_response_text}\")\n",
    "\n",
    "        # --- Update Gradio State ---\n",
    "        # Use the state potentially modified by tools\n",
    "        updated_order_from_tools = current_process_order_state['order']\n",
    "\n",
    "        # Update history for Gradio display\n",
    "        updated_history_for_gradio = current_session_history[:] # Start with original history for the turn\n",
    "        updated_history_for_gradio.append({'role': 'user', 'content': user_input_text})\n",
    "        # We might want to include tool interactions in history for debugging, but maybe not for user display\n",
    "        # For now, just add the final assistant response\n",
    "        updated_history_for_gradio.append({'role': 'assistant', 'content': agent_response_text})\n",
    "\n",
    "        return agent_response_text, updated_history_for_gradio, updated_order_from_tools\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Critical error in process_order: {str(e)}\")\n",
    "        error_message = \"I'm sorry, an unexpected error occurred during processing. Please try again later.\"\n",
    "        # Return original state on critical error\n",
    "        safe_history = current_session_history[:]\n",
    "        safe_history.append({'role': 'user', 'content': user_input_text})\n",
    "        safe_history.append({'role': 'assistant', 'content': error_message})\n",
    "        return error_message, safe_history, current_session_order\n",
    "\n",
    "# --- get_voice_audio function ---\n",
    "# ... (keep the get_voice_audio function as it was) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YQIgKJOeIE5q"
   },
   "outputs": [],
   "source": [
    "# Define retryable exceptions for Cartesia if known, otherwise use generic ones\n",
    "# Example: CARTESIA_RETRYABLE_EXCEPTIONS = (cartesia.errors.ServerError, cartesia.errors.RateLimitError, ConnectionError)\n",
    "# Using generic exceptions for now as specific Cartesia ones aren't known here.\n",
    "CARTESIA_RETRYABLE_EXCEPTIONS = (ConnectionError, TimeoutError) # Add more specific Cartesia errors if documented\n",
    "\n",
    "@tenacity_retry(\n",
    "    stop=stop_after_attempt(3),\n",
    "    wait=wait_exponential(multiplier=1, min=1, max=5),\n",
    "    retry=retry_if_exception_type(CARTESIA_RETRYABLE_EXCEPTIONS),\n",
    "    before_sleep=before_sleep_log(logger, logging.WARNING) if callable(before_sleep_log) else None,\n",
    "    reraise=True\n",
    ")\n",
    "def get_voice_audio(text_to_speak: str) -> bytes | None:\n",
    "    \"\"\"Calls Cartesia API synchronously to synthesize speech and returns WAV bytes.\"\"\"\n",
    "    global cartesia_client, CARTESIA_VOICE_ID # Access the global client and voice ID\n",
    "\n",
    "    if not text_to_speak or not text_to_speak.strip():\n",
    "        logger.warning(\"get_voice_audio received empty text.\")\n",
    "        return None\n",
    "    if not cartesia_client or not CARTESIA_VOICE_ID:\n",
    "         logger.error(\"Cartesia client or voice ID not initialized, cannot generate audio.\")\n",
    "         return None\n",
    "\n",
    "    try:\n",
    "        # Replace \"MOK 5-ha\" with \"Moksha\" for pronunciation in TTS\n",
    "        text_for_tts = re.sub(r'MOK 5-ha', 'Moksha', text_to_speak, flags=re.IGNORECASE)\n",
    "        if text_for_tts != text_to_speak:\n",
    "            logger.info(\"Applied 'MOK 5-ha' â†’ 'Moksha' pronunciation for TTS.\")\n",
    "\n",
    "        logger.info(f\"Requesting TTS from Cartesia (Voice ID: {CARTESIA_VOICE_ID}) for: '{text_for_tts[:50]}...'\")\n",
    "\n",
    "        # --- Check Cartesia Documentation for the exact method call ---\n",
    "        # This is a plausible synchronous implementation pattern:\n",
    "        audio_generator = cartesia_client.tts.bytes(\n",
    "            model_id=\"sonic-2\",\n",
    "            transcript=text_for_tts,  # Use the modified text with correct pronunciation\n",
    "            voice={\"mode\":\"id\",\n",
    "                   \"id\": CARTESIA_VOICE_ID,\n",
    "            },\n",
    "            language=\"en\",\n",
    "            # Specify desired output format and sample rate\n",
    "            output_format={\"container\":\"wav\",\n",
    "                           \"sample_rate\": 24000,\n",
    "                           \"encoding\": \"pcm_f32le\",\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Concatenate chunks from the generator for a blocking result\n",
    "        audio_data = b\"\".join(chunk for chunk in audio_generator)\n",
    "        # --- End of section requiring Cartesia documentation check ---\n",
    "\n",
    "        if not audio_data:\n",
    "            logger.warning(\"Cartesia TTS returned empty audio data.\")\n",
    "            return None\n",
    "\n",
    "        logger.info(f\"Received {len(audio_data)} bytes of WAV audio data from Cartesia.\")\n",
    "        return audio_data\n",
    "\n",
    "    # Catch specific Cartesia errors if they exist and are imported\n",
    "    # except cartesia.errors.CartesiaError as e:\n",
    "    #    logger.exception(f\"Cartesia API error during TTS generation: {e}\")\n",
    "    #    return None\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected error during TTS\n",
    "        logger.exception(f\"Unexpected error generating voice audio with Cartesia: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rsFNoUSIYjc"
   },
   "source": [
    "# Gradio Interface Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "UYT5yCeG1iBT",
    "outputId": "c7387870-329d-4c76-dab3-793978de5a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthwave '84 inspired Gradio theme created (forcing dark block/input backgrounds).\n"
     ]
    }
   ],
   "source": [
    "# Creating our own custom synthwave '84 inspired theme\n",
    "\n",
    "# Synthwave '84 Inspired Theme Definition\n",
    "# Color Palette\n",
    "synth_background_dark = \"#2a2139\"\n",
    "synth_background_med = \"#3b3269\" # Keep this defined for potential use elsewhere\n",
    "synth_text = \"#f9f7f3\"\n",
    "synth_pink = \"#ff79c6\"\n",
    "synth_cyan = \"#80ffea\"\n",
    "synth_purple = \"#bd93f9\"\n",
    "synth_orange = \"#ffb86c\"\n",
    "synth_yellow = \"#f1fa8c\"\n",
    "\n",
    "# Font\n",
    "synth_font = fonts.GoogleFont(\"Roboto Mono\")\n",
    "\n",
    "# Create the theme using .set()\n",
    "synthwave_theme = gr.themes.Default(\n",
    "    font=synth_font,\n",
    "    font_mono=synth_font,\n",
    ").set(\n",
    "    # Backgrounds\n",
    "    body_background_fill=synth_background_dark,\n",
    "    background_fill_primary=synth_background_dark,\n",
    "    background_fill_secondary=synth_background_dark, # Also set secondary body background dark\n",
    "    block_background_fill=synth_background_dark,     # CHANGED to darker background\n",
    "\n",
    "    # Text\n",
    "    body_text_color=synth_text,\n",
    "    error_text_color=synth_pink,\n",
    "\n",
    "    # Borders\n",
    "    border_color_primary=synth_purple,\n",
    "    border_color_accent=synth_cyan,\n",
    "    block_border_width=\"1px\",\n",
    "    block_border_color=synth_purple,\n",
    "\n",
    "    # Buttons\n",
    "    button_primary_background_fill=synth_purple,\n",
    "    button_primary_background_fill_hover=synth_cyan,\n",
    "    button_primary_text_color=synth_background_dark,\n",
    "    button_secondary_background_fill=synth_cyan,\n",
    "    button_secondary_background_fill_hover=synth_pink,\n",
    "    button_secondary_text_color=synth_background_dark,\n",
    "    button_cancel_background_fill=synth_orange,\n",
    "    button_cancel_text_color=synth_background_dark,\n",
    "\n",
    "    # Inputs / Sliders / etc.\n",
    "    input_background_fill=synth_background_dark, # Keep this dark too\n",
    "    input_border_color=synth_cyan,\n",
    "    input_placeholder_color=colors.gray.c500,\n",
    "    slider_color=synth_pink,\n",
    "\n",
    "    # Block appearance\n",
    "    block_label_background_fill=synth_background_med, # Labels can have the medium background\n",
    "    block_label_text_color=synth_text,\n",
    "    block_title_text_color=synth_cyan,\n",
    "    block_radius=sizes.radius_md,\n",
    "    block_shadow=\"*shadow_drop_lg\",\n",
    "\n",
    "    # Spacing\n",
    "    layout_gap=sizes.spacing_md,\n",
    ")\n",
    "\n",
    "print(\"Synthwave '84 inspired Gradio theme created (forcing dark block/input backgrounds).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload or Generate Bartender Avatar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_default_avatar = True\n",
    "\n",
    "# Default avatar URL\n",
    "default_avatar_url = \"https://github.com/gen-ai-capstone-project-bartender-agent/MOK-5-ha/blob/main/assets/bartender_avatar_ai_studio.jpeg?raw=true\"\n",
    "\n",
    "if use_default_avatar:\n",
    "    # Download default avatar\n",
    "    try:\n",
    "        response = requests.get(default_avatar_url)\n",
    "        if response.status_code == 200:\n",
    "            avatar_bytes = response.content\n",
    "            avatar_image = Image.open(io.BytesIO(avatar_bytes))\n",
    "            print(\"Using default avatar image\")\n",
    "        else:\n",
    "            print(f\"Failed to download default avatar. Status code: {response.status_code}\")\n",
    "            # Create a blank avatar as fallback\n",
    "            avatar_image = Image.new('RGB', (300, 300), color = (73, 109, 137))\n",
    "    except Exception as e:\n",
    "        print(f\"Error using default avatar: {e}\")\n",
    "        # Create a blank avatar as fallback\n",
    "        avatar_image = Image.new('RGB', (300, 300), color = (73, 109, 137))\n",
    "else:\n",
    "    # Ask user to upload an avatar\n",
    "    print(\"Please upload an avatar image:\")\n",
    "    # uploaded = files.upload()\n",
    "    # if uploaded:\n",
    "    #     avatar_key = next(iter(uploaded))\n",
    "    #     avatar_bytes = uploaded[avatar_key]\n",
    "    #     avatar_image = Image.open(io.BytesIO(avatar_bytes))\n",
    "    #     print(f\"Uploaded avatar: {avatar_key}\")\n",
    "    # else:\n",
    "    print(\"No avatar uploaded, using default\")\n",
    "    # Create a blank avatar as fallback\n",
    "    avatar_image = Image.new('RGB', (300, 300), color = (73, 109, 137))\n",
    "\n",
    "# Display the avatar\n",
    "plt.imshow(avatar_image)\n",
    "plt.axis('off')\n",
    "plt.title(\"Bartender Avatar\")\n",
    "plt.show()\n",
    "\n",
    "# Save avatar for use in Gradio\n",
    "avatar_path = \"bartender_avatar.jpg\"\n",
    "avatar_image.save(avatar_path)\n",
    "print(f\"Avatar saved to {avatar_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KgbB7vlLIdiG"
   },
   "outputs": [],
   "source": [
    "def handle_gradio_input(\n",
    "    user_input: str,\n",
    "    session_history_state: List[Dict[str, str]],\n",
    "    session_order_state: List[Dict[str, float]]\n",
    ") -> Tuple[str, List[Dict[str, str]], List[Dict[str, str]], List[Dict[str, float]], Any]:\n",
    "    \"\"\"\n",
    "    Gradio callback: Takes input/state, calls logic & TTS, returns updates.\n",
    "    \"\"\"\n",
    "    logger.info(f\"Gradio input: '{user_input}'\")\n",
    "    logger.debug(f\"Received session history state (len {len(session_history_state)}): {session_history_state}\")\n",
    "    logger.debug(f\"Received session order state (len {len(session_order_state)}): {session_order_state}\")\n",
    "\n",
    "    # Call text processing logic first\n",
    "    response_text, updated_history, updated_order = process_order(\n",
    "        user_input,\n",
    "        session_history_state,\n",
    "        session_order_state\n",
    "    )\n",
    "\n",
    "    # --- Get Voice Audio ---\n",
    "    audio_data = None # Default to None\n",
    "    # Check if there is a non-empty response text to synthesize\n",
    "    if response_text and response_text.strip():\n",
    "         audio_data = get_voice_audio(response_text) # Call the imported function\n",
    "         if audio_data is None:\n",
    "             logger.warning(\"Failed to get audio data from get_voice_audio.\")\n",
    "             # Optional: Add indication to user? E.g., append \"[Audio failed]\" to response_text\n",
    "    else:\n",
    "        logger.info(\"No response text generated, skipping TTS.\")\n",
    "    # --- End Get Voice Audio ---\n",
    "\n",
    "    # Return updates including audio data (which might be None)\n",
    "    return \"\", updated_history, updated_history, updated_order, audio_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "q8GnZARHIhx2"
   },
   "outputs": [],
   "source": [
    "def clear_chat_state() -> Tuple[List, List, List, None]:\n",
    "    \"\"\"Clears UI/session state including audio.\"\"\"\n",
    "    logger.info(\"Clear button clicked - Resetting session state.\")\n",
    "    # Return empty lists for Chatbot/history/order, and None for the audio component\n",
    "    return [], [], [], None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDudVg8TIlvu"
   },
   "source": [
    "# Launch the Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7E6cgjryIqdV"
   },
   "outputs": [],
   "source": [
    "def launch_bartender_interface():\n",
    "    theme = gr.themes.Citrus()\n",
    "\n",
    "    with gr.Blocks(theme=synthwave_theme) as demo:\n",
    "        gr.Markdown(\"# MOK 5-ha Bartending Agent\")\n",
    "        gr.Markdown(\"Welcome to MOK 5-ha! Ask me for a drink or check your order.\")\n",
    "\n",
    "        # --- Define Session State Variables ---\n",
    "        history_state = gr.State([])\n",
    "        order_state = gr.State([])\n",
    "\n",
    "        # --- Restructured Main Row with 2 Columns (Equal Scaling) ---\n",
    "        with gr.Row():\n",
    "\n",
    "            # --- Column 1: Avatar Image ---\n",
    "            # Scale is relative to other columns in the same row\n",
    "            with gr.Column(scale=1, min_width=200): # Keep scale=1\n",
    "                gr.Image(\n",
    "                    value=avatar_path,  # Use the saved avatar path\n",
    "                    label=\"Bartender Avatar\",\n",
    "                    show_label=False,\n",
    "                    interactive=False,\n",
    "                    height=600, # Adjust as desired\n",
    "                    elem_classes=[\"avatar-image\"]\n",
    "                )\n",
    "\n",
    "            # --- Column 2: Chat Interface ---\n",
    "            with gr.Column(scale=1): # <-- Changed scale from 3 to 1\n",
    "                chatbot_display = gr.Chatbot(\n",
    "                    [],\n",
    "                    elem_id=\"chatbot\",\n",
    "                    label=\"Conversation\",\n",
    "                    height=489, # Keep or adjust height for rectangular shape\n",
    "                    type=\"messages\"\n",
    "                )\n",
    "                agent_audio_output = gr.Audio(\n",
    "                    label=\"Agent Voice\",\n",
    "                    autoplay=True,\n",
    "                    streaming=False,\n",
    "                    format=\"wav\",\n",
    "                    show_label=True,\n",
    "                    interactive=False\n",
    "                )\n",
    "                msg_input = gr.Textbox(\n",
    "                    label=\"Your Order / Message\",\n",
    "                    placeholder=\"What can I get for you? (e.g., 'I'd like a Margarita', 'Show my order')\"\n",
    "                )\n",
    "                with gr.Row():\n",
    "                    clear_btn = gr.Button(\"Clear Conversation\")\n",
    "                    submit_btn = gr.Button(\"Send\", variant=\"primary\")\n",
    "\n",
    "        # --- Event Handlers (Remain the same) ---\n",
    "        submit_inputs = [msg_input, history_state, order_state]\n",
    "        submit_outputs = [msg_input, chatbot_display, history_state, order_state, agent_audio_output]\n",
    "        msg_input.submit(handle_gradio_input, submit_inputs, submit_outputs)\n",
    "        submit_btn.click(handle_gradio_input, submit_inputs, submit_outputs)\n",
    "\n",
    "        clear_outputs = [chatbot_display, history_state, order_state, agent_audio_output]\n",
    "        clear_btn.click(clear_chat_state, None, clear_outputs)\n",
    "\n",
    "    # Launch the interface\n",
    "    demo.launch(debug=True, share=True)  # share=True to make it accessible via a public URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjZFOOFpItNX"
   },
   "source": [
    "# Run the Bartending Agent ðŸŽ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BBPtIMysHwnz",
    "outputId": "90990cb8-1f04-487a-8d71-4efbd62b8737"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:16:42,262 - httpx - INFO - HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "2025-04-18 21:16:42,651 - httpx - INFO - HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "2025-04-18 21:16:42,671 - httpx - INFO - HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:16:42,919 - httpx - INFO - HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://9e1ffc7ee9e1a7540d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:16:44,252 - httpx - INFO - HTTP Request: HEAD https://9e1ffc7ee9e1a7540d.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://9e1ffc7ee9e1a7540d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:17:51,151 - __main__ - INFO - Gradio input: 'Hi'\n",
      "2025-04-18 21:17:51,195 - __main__ - INFO - Processing user input for session: Hi\n",
      "2025-04-18 21:17:51,907 - __main__ - INFO - Final agent response: Welcome to MOK 5-ha! What can I get for you?\n",
      "2025-04-18 21:17:51,909 - __main__ - INFO - Applied 'MOK 5-ha' â†’ 'Moksha' pronunciation for TTS.\n",
      "2025-04-18 21:17:51,911 - __main__ - INFO - Requesting TTS from Cartesia (Voice ID: 6f84f4b8-58a2-430c-8c79-688dad597532) for: 'Welcome to Moksha! What can I get for you?...'\n",
      "2025-04-18 21:17:52,413 - httpx - INFO - HTTP Request: POST https://api.cartesia.ai/tts/bytes \"HTTP/1.1 200 OK\"\n",
      "2025-04-18 21:17:53,069 - __main__ - INFO - Received 179046 bytes of WAV audio data from Cartesia.\n",
      "2025-04-18 21:18:17,902 - __main__ - INFO - Gradio input: 'What's your name?'\n",
      "2025-04-18 21:18:17,904 - __main__ - INFO - Processing user input for session: What's your name?\n",
      "2025-04-18 21:18:18,483 - __main__ - INFO - Final agent response: I'm the Bartender-Bot! I can tell you about the menu and take your order.\n",
      "2025-04-18 21:18:18,484 - __main__ - INFO - Requesting TTS from Cartesia (Voice ID: 6f84f4b8-58a2-430c-8c79-688dad597532) for: 'I'm the Bartender-Bot! I can tell you about the me...'\n",
      "2025-04-18 21:18:18,883 - httpx - INFO - HTTP Request: POST https://api.cartesia.ai/tts/bytes \"HTTP/1.1 200 OK\"\n",
      "2025-04-18 21:18:20,124 - __main__ - INFO - Received 299418 bytes of WAV audio data from Cartesia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://9e1ffc7ee9e1a7540d.gradio.live\n"
     ]
    }
   ],
   "source": [
    "# Launch the interface when this cell is executed\n",
    "launch_bartender_interface()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
