{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# Remove conflicting packages from the Kaggle base environment.\n!pip uninstall -qqy kfp jupyterlab libpysal thinc spacy fastai ydata-profiling google-cloud-bigquery google-generativeai\n# Install langgraph and the packages used in this lab.\n!pip install -qU 'langgraph==0.3.21' 'langchain-google-genai==2.1.2' 'langgraph-prebuilt==0.1.7'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:31:51.258467Z","iopub.execute_input":"2025-04-16T05:31:51.258796Z","iopub.status.idle":"2025-04-16T05:32:25.384879Z","shell.execute_reply.started":"2025-04-16T05:31:51.258768Z","shell.execute_reply":"2025-04-16T05:32:25.383739Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping kfp as it is not installed.\u001b[0m\u001b[33m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# API Key Setup","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nos.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:32:25.386917Z","iopub.execute_input":"2025-04-16T05:32:25.387987Z","iopub.status.idle":"2025-04-16T05:32:25.597815Z","shell.execute_reply.started":"2025-04-16T05:32:25.387951Z","shell.execute_reply":"2025-04-16T05:32:25.596813Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Defining Core Instructions","metadata":{}},{"cell_type":"code","source":"from typing import Annotated\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph.message import add_messages\n\n\nclass OrderState(TypedDict):\n    \"\"\"State representing the customer's order conversation.\"\"\"\n\n    # The chat conversation. This preserves the conversation history\n    # between nodes. The `add_messages` annotation indicates to LangGraph\n    # that state is updated by appending returned messages, not replacing\n    # them.\n    messages: Annotated[list, add_messages]\n\n    # The customer's in-progress order.\n    order: list[str]\n\n    # Flag indicating that the order is placed and completed.\n    finished: bool\n\n\n# The system instruction defines how the chatbot is expected to behave and includes\n# rules for when to call different functions, as well as rules for the conversation, such\n# as tone and what is permitted for discussion.\nBARTENDERBOT_SYSINT = (\n    \"system\",  # 'system' indicates the message is a system instruction.\n    \"You are a Bartender-Bot, an interactive drink ordering system. A human will talk to you about the \"\n    \"available products you have and you will answer any questions about menu items and their prices.\"\n    \"Be conversational and friendly with the customer as they may intearct with you.\"\n    \"The customer will place an order for 1 or more items from the menu, which you will structure \"\n    \"and send to the ordering system after confirming the order with the human. \"\n    \"\\n\\n\"\n    \"Add items to the customer's order with add_to_order, and reset the order with clear_order. \"\n    \"To see the contents of the order so far, call get_order (this is shown to you, not the user) \"\n    \"Always confirm_order with the user (double-check) before calling place_order. Calling confirm_order will \"\n    \"display the order items to the user and returns their response to seeing the list. Their response may contain modifications. \"\n    \"Always verify and respond with drink and modifier names from the MENU before adding them to the order. \"\n    \"If you are unsure a drink or modifier matches those on the MENU, ask a question to clarify or redirect. \"\n    \"You only have the modifiers listed on the menu. \"\n    \"Once the customer has finished ordering items, Call confirm_order to ensure it is correct then make \"\n    \"any necessary updates and then call place_order. Once place_order has returned, thank the user for their business and \"\n    \"politely say their order will be ready shortly!\"\n    \"\\n\\n\"\n)\n\n# This is the message with which the system opens the conversation.\nWELCOME_MSG = \"Welcome to Mok-5-Sha. How may I serve you today?\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:32:25.598842Z","iopub.execute_input":"2025-04-16T05:32:25.599151Z","iopub.status.idle":"2025-04-16T05:32:27.325433Z","shell.execute_reply.started":"2025-04-16T05:32:25.599121Z","shell.execute_reply":"2025-04-16T05:32:27.324256Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Live Menu","metadata":{}},{"cell_type":"code","source":"from langchain_core.tools import tool\n\n\n@tool\ndef get_menu() -> str:\n    \"\"\"Provide the latest up-to-date menu.\"\"\"\n    # Note that this is just hard-coded text, but you could connect this to a live stock\n    # database, or you could use Gemini's multi-modal capabilities and take live photos of\n    # your cafe's chalk menu or the products on the counter and assmble them into an input.\n\n    return \"\"\"\n    MENU:\n    Cocktails with Liquor:\n    Daiquiri - $10.00\n    Martini - $13.00\n    Long Island - $12.00\n    Old Fashioned - $12.00 \n    Negroni - $11.00\n    Cosmopolitan - $12.00\n    Manhattan - $12.00\n\n    Beer:\n    Tap Beer - $5.00\n    Classic Brew - $5.00\n    IPA - $6.00\n\n    Non-Alcoholic Beverages:\n    Water - $1.00\n    Iced Tea - $2.00\n    Lemonade - $2.00\n    Soda - $3.00\n\n    Modifiers:\n    Liquor Options: Vodka, Tequila, Gin, Whiskey, Rum, Brandy; Default option: Vodka\n    Special requests: any reasonable modification that does not involve items not on the menu, for example: 'shaken', 'stirred', 'neat', 'dry', etc.\n\n    “neat” means no ice, straight from the bottle.\n    “on the rocks” means served with ice.\n    “dry” is used for martinis to specify less vermouth.\n    “dirty” means adding olive juice to a martini.\n    “perfect” is a 50/50 mix of dry and sweet vermouth, often for a Manhattan.\n    “Chaser” means a separate drink to follow, typically non-alcoholic.\n\n    Reccomendations: a suggestion to the best drink according to the customers preference, for example: 'classy', 'vintage', 'sobering', etc.\n\n    \"sobering\" means a customer wants a non-alcoholic drink.\n    \"classy\" drink is typically one that's perceived as sophisticated, elegant, and refined.\n    \"fruity\" describes a flavor profile that is reminiscent of fruit, often characterized by a balance of sweetness, acidity, and a refreshing quality.\n    \"strong\" contains a larger proportion of alcohol compared to other ingredients like mixers.\n    \"burning\" refers to a strong, hot, or irritating sensation in the throat or mouth when drinking, primarily due to the high alcohol content, especially in spirits like whiskey or vodka.\n    \n  \"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:32:27.326576Z","iopub.execute_input":"2025-04-16T05:32:27.327217Z","iopub.status.idle":"2025-04-16T05:32:27.369388Z","shell.execute_reply.started":"2025-04-16T05:32:27.327179Z","shell.execute_reply":"2025-04-16T05:32:27.367740Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Order Handling","metadata":{}},{"cell_type":"code","source":"from collections.abc import Iterable\nfrom random import randint\n\nfrom langchain_core.messages.tool import ToolMessage\n\n@tool\ndef add_to_order(drink: str, modifiers: Iterable[str]) -> str:\n    \"\"\"Adds the specified drink to the customer's order, including any modifiers.\n\n    Returns:\n      The updated order in progress.\n    \"\"\"\n\n\n@tool\ndef confirm_order() -> str:\n    \"\"\"Asks the customer if the order is correct.\n\n    Returns:\n      The user's free-text response.\n    \"\"\"\n\n@tool\ndef get_order() -> str:\n    \"\"\"Returns the users order so far. One item per line.\"\"\"\n\n\n@tool\ndef clear_order():\n    \"\"\"Removes all items from the user's order.\"\"\"\n\n\n@tool\ndef place_order() -> int:\n    \"\"\"Sends the order to the barista for fulfillment.\n\n    Returns:\n      The estimated number of minutes until the order is ready.\n    \"\"\"\n\ndef order_node(state: OrderState) -> OrderState:\n    \"\"\"The ordering node. This is where the order state is manipulated.\"\"\"\n    tool_msg = state.get(\"messages\", [])[-1]\n    order = state.get(\"order\", [])\n    outbound_msgs = []\n    order_placed = False\n\n    for tool_call in tool_msg.tool_calls:\n\n        if tool_call[\"name\"] == \"add_to_order\":\n\n            # Each order item is just a string. This is where it assembled as \"drink (modifiers, ...)\".\n            modifiers = tool_call[\"args\"][\"modifiers\"]\n            modifier_str = \", \".join(modifiers) if modifiers else \"no modifiers\"\n\n            order.append(f'{tool_call[\"args\"][\"drink\"]} ({modifier_str})')\n            response = \"\\n\".join(order)\n\n        elif tool_call[\"name\"] == \"confirm_order\":\n            print(\"Your order:\")\n            if not order:\n                print(\"  (no items)\")\n\n            for drink in order:\n                print(f\"  {drink}\")\n\n            response = input(\"Is this correct? \")\n\n        elif tool_call[\"name\"] == \"get_order\":\n\n            response = \"\\n\".join(order) if order else \"(no order)\"\n\n        elif tool_call[\"name\"] == \"clear_order\":\n\n            order.clear()\n            response = None\n\n        elif tool_call[\"name\"] == \"place_order\":\n\n            order_text = \"\\n\".join(order)\n            print(\"Sending order to kitchen!\")\n            print(order_text)\n\n            # TODO(you!): Implement cafe.\n            order_placed = True\n            response = randint(1, 5)  # ETA in minutes\n\n        else:\n            raise NotImplementedError(f'Unknown tool call: {tool_call[\"name\"]}')\n\n        # Record the tool results as tool messages.\n        outbound_msgs.append(\n            ToolMessage(\n                content=response,\n                name=tool_call[\"name\"],\n                tool_call_id=tool_call[\"id\"],\n            )\n        )\n\n    return {\"messages\": outbound_msgs, \"order\": order, \"finished\": order_placed}\n\n\ndef maybe_route_to_tools(state: OrderState) -> str:\n    \"\"\"Route between chat and tool nodes if a tool call is made.\"\"\"\n    if not (msgs := state.get(\"messages\", [])):\n        raise ValueError(f\"No messages found when parsing state: {state}\")\n\n    msg = msgs[-1]\n\n    if state.get(\"finished\", False):\n        # When an order is placed, exit the app. The system instruction indicates\n        # that the chatbot should say thanks and goodbye at this point, so we can exit\n        # cleanly.\n        return END\n\n    elif hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n        # Route to `tools` node for any automated tool calls first.\n        if any(\n            tool[\"name\"] in tool_node.tools_by_name.keys() for tool in msg.tool_calls\n        ):\n            return \"tools\"\n        else:\n            return \"ordering\"\n\n    else:\n        return \"human\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-16T05:32:27.371526Z","iopub.execute_input":"2025-04-16T05:32:27.371893Z","iopub.status.idle":"2025-04-16T05:32:27.405162Z","shell.execute_reply.started":"2025-04-16T05:32:27.371866Z","shell.execute_reply":"2025-04-16T05:32:27.404195Z"}},"outputs":[],"execution_count":5}]}